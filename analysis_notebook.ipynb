{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Explainable Object Detection Analysis\n",
        "\n",
        "This notebook provides interactive exploration of the explainable object detection framework.\n",
        "\n",
        "## Contents\n",
        "1. Setup and Initialization\n",
        "2. Object Detection with YOLOv8\n",
        "3. CLIP Semantic Analysis\n",
        "4. Grad-CAM Saliency Maps\n",
        "5. LLaVA Explanations\n",
        "6. Complete Pipeline Run\n",
        "7. Evaluation Analysis\n",
        "8. Failure Case Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import torch\n",
        "\n",
        "# Enable inline plots\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = [12, 8]\n",
        "\n",
        "# Check GPU\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Initialize Pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from config import get_default_config, update_config_for_cpu\n",
        "from pipeline import ExplainableDetectionPipeline, create_pipeline\n",
        "\n",
        "# Create pipeline (set use_llava=True if you have enough GPU memory)\n",
        "pipeline = create_pipeline(use_gpu=True, use_llava=False)\n",
        "\n",
        "print(\"Pipeline initialized!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Object Detection with YOLOv8\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create or load a test image\n",
        "test_img = np.zeros((480, 640, 3), dtype=np.uint8)\n",
        "test_img[:] = (180, 180, 180)  # Gray background\n",
        "\n",
        "# Add colored shapes\n",
        "cv2.rectangle(test_img, (50, 50), (180, 180), (255, 0, 0), -1)   # Blue\n",
        "cv2.circle(test_img, (350, 150), 80, (0, 255, 0), -1)           # Green\n",
        "cv2.rectangle(test_img, (500, 100), (620, 250), (0, 0, 255), -1) # Red\n",
        "\n",
        "# Or load your own image:\n",
        "# test_img = cv2.imread('your_image.jpg')\n",
        "# test_img = cv2.cvtColor(test_img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "plt.imshow(test_img)\n",
        "plt.title('Test Image')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run detection\n",
        "detector = pipeline.detector\n",
        "detection_result = detector.detect(test_img)\n",
        "\n",
        "print(f\"Found {detection_result.num_detections} detections\")\n",
        "for i, det in enumerate(detection_result.detections):\n",
        "    print(f\"  {i+1}. {det.class_name}: {det.confidence:.1%} at {det.bbox}\")\n",
        "\n",
        "# Visualize detections\n",
        "vis_img = detector.visualize_detections(detection_result)\n",
        "plt.imshow(vis_img)\n",
        "plt.title(f'YOLO Detections ({detection_result.num_detections} objects)')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Complete Pipeline Run & Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run complete pipeline\n",
        "result = pipeline.process_image(\n",
        "    test_img,\n",
        "    max_detections=10,\n",
        "    generate_explanations=True,\n",
        "    compute_saliency=True,\n",
        "    run_evaluation=True\n",
        ")\n",
        "\n",
        "print(f\"Processing time: {result.processing_time:.2f}s\")\n",
        "print(f\"Detections: {result.num_detections}\")\n",
        "\n",
        "# Detailed results\n",
        "for i, det in enumerate(result.detections):\n",
        "    print(f\"\\n{'='*50}\")\n",
        "    print(f\"DETECTION {i+1}: {det.detection.class_name}\")\n",
        "    print(f\"{'='*50}\")\n",
        "    print(f\"Confidence: {det.detection.confidence:.1%}\")\n",
        "    \n",
        "    if det.semantic_analysis and det.semantic_analysis.semantic_match:\n",
        "        match = det.semantic_analysis.semantic_match\n",
        "        print(f\"CLIP Alignment: {match.alignment_score:.3f}\")\n",
        "        print(f\"Top CLIP matches: {match.top_k_classes[:3]}\")\n",
        "    \n",
        "    if det.explanation:\n",
        "        print(f\"Explanation: {det.explanation.explanation_text[:100]}...\")\n",
        "    \n",
        "    if det.evaluation:\n",
        "        print(f\"Quality Score: {det.evaluation.get_overall_score():.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize comprehensive results\n",
        "vis = pipeline.visualize_result(result, 'outputs/pipeline_result.png')\n",
        "plt.figure(figsize=(16, 12))\n",
        "plt.imshow(vis)\n",
        "plt.axis('off')\n",
        "plt.title('Complete Pipeline Results')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Save Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save all results\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "\n",
        "# Save JSON results\n",
        "result.save('outputs/analysis_result.json')\n",
        "print(\"Saved results to outputs/analysis_result.json\")\n",
        "\n",
        "# Analyze misalignments between YOLO and CLIP\n",
        "mismatches = pipeline.analyze_misalignments(result)\n",
        "if mismatches:\n",
        "    print(f\"\\nFound {len(mismatches)} potential misclassifications\")\n",
        "    for mm in mismatches:\n",
        "        print(f\"  YOLO: {mm['yolo_class']} vs CLIP: {mm['clip_top_class']}\")\n",
        "else:\n",
        "    print(\"\\nNo misalignments - YOLO and CLIP agree!\")\n",
        "\n",
        "print(\"\\nAnalysis complete!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
